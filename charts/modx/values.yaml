
# Labels settings in namespace
namespace:
  annotations: {}
  labels:
    # Enforce Pod Security Standards with Namespace Labels
    # https://kubernetes.io/docs/tasks/configure-pod-container/enforce-standards-namespace-labels/
    - key: pod-security.kubernetes.io/enforce
      value: baseline
    # - key: pod-security.kubernetes.io/enforce-version
    #   value: latest
    - key: pod-security.kubernetes.io/audit
      value: baseline
    # - key: pod-security.kubernetes.io/audit-version
    #   value: latest
    - key: pod-security.kubernetes.io/warn
      value: baseline
    # - key: pod-security.kubernetes.io/warn-version
    #   value: latest

imagePullSecrets:
# - name: "image-pull-secret"

rbac:
  # Whether to create the role and role binding to give all permissions to the namespace.
  create: true
  # Whether to create the cluster role binding to give administrator permissions
  clusterAdministrator: true
  # Name of the ClusterRole.
  clusterAdministratorName:

# This section builds out the service account more information can be found here: https://kubernetes.io/docs/concepts/security/service-accounts/
serviceAccounts:
  phpfpm:
    create: true
    # Automatically mount a ServiceAccount's API credentials?
    # automount: true
    # Annotations to add to the service account
    annotations: {}
    name:
    labels:
    imagePullSecrets: []
  nginx:
    create: true
    # Automatically mount a ServiceAccount's API credentials?
    # automount: true
    # Annotations to add to the service account
    annotations: { }
    name:
    labels:
    imagePullSecrets: [ ]
  labelnamespace:
    create: true
    # Automatically mount a ServiceAccount's API credentials?
    # automount: true
    # Annotations to add to the service account
    annotations: { }
    name:
    labels:
    imagePullSecrets: [ ]


phpfpm:
  ## Use a ClusterRole (and ClusterRoleBinding)
  ## - If set to false - we define a Role and RoleBinding in the defined namespaces ONLY
  ## This makes alertmanager work - for users who do not have ClusterAdmin privs, but wants alertmanager to operate on their own namespaces, instead of clusterwide.
  useClusterRole: true

  ## Set to a rolename to use existing role - skipping role creating - but still doing serviceaccount and rolebinding to the rolename set here.
  useExistingRole: false

  ## modx container name
  name: php-fpm
  ## modx container image
  labels: {}
  image:
    repository: artyomyudin/modx
    # This sets the pull policy for images.
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: 3.1.1
    # This is for the secrets for pulling an image from a private repository more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    imagePullSecrets: [ ]


  ## priorityClassName
  priorityClassName: ""

  ## Additional container arguments
  extraArgs: {}

  ## Additional InitContainers to initialize the pod
  extraInitContainers: []

  tolerations: []

  ## Node labels for modx pod assignment
  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/
  nodeSelector: { }

  ## Pod affinity
  affinity: { }

  ## PodDisruptionBudget settings
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/disruptions/
  podDisruptionBudget:
    enabled: false
    maxUnavailable: 1

  ## Use an alternate scheduler, e.g. "stork".
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  # schedulerName:

  persistentVolume:
    ## If true, modx will create/use a Persistent Volume Claim
    ## If false, use emptyDir
    enabled: true
    accessModes:
      - ReadWriteOnce
    annotations: {}
    existingClaim: ""
    mountPath: /app
    size: 2Gi
    storageClass: ""


  podAnnotations: { }
  podLabels: { }
  ## Specify if a Pod Security Policy for node-exporter must be created
  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/
  podSecurityPolicy:
    annotations: { }
      ## Specify pod annotations
      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor
      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp
      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl
      ##
      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'
    # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'
    # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'

  ## Use a StatefulSet if replicaCount needs to be greater than 1 (see below)
  replicaCount: 1

  statefulSet:
    ## If true, use a statefulset instead of a deployment for pod management.
    ## This allows to scale replicas to more than 1 pod
    enabled: false
    podManagementPolicy: OrderedReady
    ## modx headless service to use for the statefulset
    headless:
      annotations: { }
      labels: { }
      ## Enabling peer mesh service end points for enabling the HA modx
      ## Ref: https://github.com/prometheus/alertmanager/blob/master/README.md
      # enableMeshPeer : true
      servicePort: 9000

  ## modx resource requests and limits
  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/
  resources: { }
    # limits:
    #   cpu: 10m
    #   memory: 32Mi
    # requests:
  #   cpu: 10m
  #   memory: 32Mi

  ## Security context to be added to modx pods
  podSecurityContext:
    #fsGroupChangePolicy: Always
    #supplementalGroups: [ ]
    #fsGroup: 1001

  containerSecurityContext:
    seLinuxOptions: {}
    runAsUser: 1001
    #runAsUser: 0
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"


  service:
    annotations: { }
    labels: { }
    clusterIP: ""
    loadBalancerIP: ""
    loadBalancerSourceRanges: [ ]
    servicePort: 9000
    sessionAffinity: None
    type: ClusterIP


nginx:
  ## If false, nginx will not be installed
  enabled: true
  ## nginx container name
  name: nginx
  labels: {}
  ## nginx container image
  image:
    repository: artyomyudin/nginx
    tag: 1.22.1
    pullPolicy: IfNotPresent

  tolerations: []

  ## Node labels for nginx pod assignment
  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/
  nodeSelector: { }
  ## Pod affinity
  affinity: { }
  ## PodDisruptionBudget settings
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/disruptions/
  podDisruptionBudget:
    enabled: false
    maxUnavailable: 1
  ## Use an alternate scheduler, e.g. "stork".
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  # schedulerName:

  persistentVolume:
    ## If true, nginx will create/use a Persistent Volume Claim
    ## If false, use emptyDir
    enabled: true
    accessModes:
      - ReadWriteOnce
    annotations: {}
    existingClaim: ""
    mountPath: /app
    size: 2Gi
    storageClass: ""


  podAnnotations: { }
  podLabels: { }
  ## Specify if a Pod Security Policy for node-exporter must be created
  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/
  podSecurityPolicy:
    annotations: { }
      ## Specify pod annotations
      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor
      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp
      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl
      ##
      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'
    # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'
    # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'

  ## Use a StatefulSet if replicaCount needs to be greater than 1 (see below)
  replicaCount: 1

  statefulSet:
    ## If true, use a statefulset instead of a deployment for pod management.
    ## This allows to scale replicas to more than 1 pod
    enabled: false
    podManagementPolicy: OrderedReady
    ## modx headless service to use for the statefulset
    headless:
      annotations: { }
      labels: { }
      ## Enabling peer mesh service end points for enabling the HA nginx
      ## Ref: https://github.com/prometheus/alertmanager/blob/master/README.md
      # enableMeshPeer : true
      servicePort: 80

  ## modx resource requests and limits
  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/
  resources: { }
    # limits:
    #   cpu: 10m
    #   memory: 32Mi
    # requests:
  #   cpu: 10m
  #   memory: 32Mi

  ## Security context to be added to nginx pods
  podSecurityContext:
    runAsUser: 65534
    runAsNonRoot: true
    runAsGroup: 65534
    fsGroup: 65534

  containerSecurityContext:
  #  seLinuxOptions: {}
  #  runAsUser: 1001
  #  #runAsUser: 0
  #  runAsGroup: 1001
  #  runAsNonRoot: true
  #  privileged: false
  #  readOnlyRootFilesystem: true
  #  allowPrivilegeEscalation: false
  #  capabilities:
  #    drop: ["ALL"]
  #  seccompProfile:
  #    type: "RuntimeDefault"

  service:
    annotations: { }
    labels: { }
    clusterIP: ""
    loadBalancerIP: ""
    loadBalancerSourceRanges: [ ]
    servicePort: 80
    sessionAffinity: None
    type: ClusterIP



kubectl:
  image:
    repository: docker.io/bitnami/kubectl
    # Digest value example: sha256:d238835e151cec91c6a811fe3a89a66d3231d9f64d09e5f3c49552672d271f38.
    # If used, it will take precedence over the kubectl.image.tag.
    # digest:
    # kubectl image tag. If used, it will take precedence over the cluster Kubernetes version.
    # tag: 1.16.15
  # Container Level Security Context for the 'kubectl' container of the crd jobs. Optional.
  # See: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  containerSecurityContext: {}
  # Resource requests/limits to specify for the upgrade/cleanup job. Optional
  resources: {}
  # Annotations to set for the upgrade/cleanup job. Optional.
  annotations: {}
  # Labels to set for the upgrade/cleanup job. Optional.
  labels: {}


labelnamespace:
  ## Use a ClusterRole (and ClusterRoleBinding)
  ## - If set to false - we define a Role and RoleBinding in the defined namespaces ONLY
  ## This makes alertmanager work - for users who do not have ClusterAdmin privs, but wants alertmanager to operate on their own namespaces, instead of clusterwide.
  useClusterRole: true

  ## Set to a rolename to use existing role - skipping role creating - but still doing serviceaccount and rolebinding to the rolename set here.
  useExistingRole: false

  name: label-ns
  containerSecurityContext:
    seLinuxOptions: { }
    runAsUser: 1001
    #runAsUser: 0
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: [ "ALL" ]
    seccompProfile:
      type: "RuntimeDefault"



## This is to override the chart name.
nameOverride: ""
fullnameOverride: ""
#
#
#
#podSecurityContext: {}
#  #fsGroupChangePolicy: Always
#  #supplementalGroups: [ ]
#  #fsGroup: 1001
#
#containerSecurityContext:
#  seLinuxOptions: {}
#  runAsUser: 1001
#  #runAsUser: 0
#  runAsGroup: 1001
#  runAsNonRoot: true
#  privileged: false
#  readOnlyRootFilesystem: true
#  allowPrivilegeEscalation: false
#  capabilities:
#    drop: ["ALL"]
#  seccompProfile:
#    type: "RuntimeDefault"
#
## The number of seconds to allow for graceful termination of the pod. Optional.
terminationGracePeriodSeconds: 3600